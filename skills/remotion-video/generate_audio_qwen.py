#!/usr/bin/env python3
"""
vLLM-Omni Qwen3-TTS éŸ³é¢‘ç”Ÿæˆè„šæœ¬ï¼ˆæ”¯æŒæ–­ç‚¹ç»­ä½œï¼‰

ç‰¹æ€§ï¼š
- æ£€æµ‹å·²å­˜åœ¨çš„éŸ³é¢‘æ–‡ä»¶ï¼Œè‡ªåŠ¨è·³è¿‡
- å®žæ—¶æ˜¾ç¤ºç”Ÿæˆè¿›åº¦
- ç”Ÿæˆå¤±è´¥æ—¶ä¿ç•™å·²å®Œæˆçš„éƒ¨åˆ†
- è‡ªåŠ¨æ›´æ–° Remotion é…ç½®æ–‡ä»¶
- æ”¯æŒæœ¬åœ°éƒ¨ç½²çš„ vLLM-Omni æœåŠ¡å™¨

ç”¨æ³•ï¼š
    python generate_audio_qwen.py

çŽ¯å¢ƒå˜é‡ï¼š
    VLLM_BASE_URL: vLLM-Ommi æœåŠ¡å™¨åœ°å€ï¼ˆé»˜è®¤: http://localhost:8000/v1ï¼‰
    VLLM_MODEL_NAME: æ¨¡åž‹åç§°ï¼ˆé»˜è®¤: Qwen/Qwen3-TTS-12Hz-0.6B-CustomVoiceï¼‰
    VLLM_VOICE: é¢„è®¾è¯­éŸ³åç§°ï¼ˆé»˜è®¤: Vivianï¼‰

ä¾èµ–ï¼š
    pip install openai>=1.0.0
"""

import os
import subprocess
from pathlib import Path
from openai import OpenAI

# ä»ŽçŽ¯å¢ƒå˜é‡è¯»å–é…ç½®
VLLM_BASE_URL = os.environ.get("VLLM_BASE_URL", "http://localhost:8000/v1")
VLLM_MODEL_NAME = os.environ.get(
    "VLLM_MODEL_NAME", "Qwen/Qwen3-TTS-12Hz-0.6B-CustomVoice"
)
VLLM_VOICE = os.environ.get("VLLM_VOICE", "Vivian")

# åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯
client = OpenAI(api_key="EMPTY", base_url=VLLM_BASE_URL)

# åœºæ™¯é…ç½® - æ¯ä¸ªåœºæ™¯åŒ…å« idã€titleã€text
SCENES = [
    {"id": "01-intro", "title": "å¼€åœº", "text": "æ¬¢è¿Žè§‚çœ‹æœ¬æœŸè§†é¢‘..."},
    {"id": "02-concept", "title": "æ ¸å¿ƒæ¦‚å¿µ", "text": "ä»Šå¤©æˆ‘ä»¬æ¥è®²..."},
    {"id": "03-demo", "title": "æ¼”ç¤º", "text": "è®©æˆ‘ä»¬çœ‹ä¸€ä¸ªä¾‹å­..."},
    {"id": "04-summary", "title": "æ€»ç»“", "text": "æ„Ÿè°¢è§‚çœ‹ï¼Œä¸‹æœŸè§ï¼"},
]

OUTPUT_DIR = Path(__file__).parent.parent / "public" / "audio"
CONFIG_FILE = Path(__file__).parent.parent / "src" / "audioConfig.ts"


def get_audio_duration(file_path: Path) -> float:
    """ç”¨ ffprobe èŽ·å–éŸ³é¢‘æ—¶é•¿"""
    result = subprocess.run(
        [
            "ffprobe",
            "-v",
            "quiet",
            "-show_entries",
            "format=duration",
            "-of",
            "default=noprint_wrappers=1:nokey=1",
            str(file_path),
        ],
        capture_output=True,
        text=True,
    )
    return float(result.stdout.strip()) if result.stdout.strip() else 0


def generate_audio(scene: dict) -> dict:
    """ä½¿ç”¨ vLLM-Ommi API ç”ŸæˆéŸ³é¢‘"""
    output_file = OUTPUT_DIR / f"{scene['id']}.mp3"

    try:
        # è°ƒç”¨ OpenAI å…¼å®¹ API
        response = client.audio.speech.create(
            model=VLLM_MODEL_NAME,
            voice=VLLM_VOICE,
            input=scene["text"],
            response_format="mp3",
        )

        # ä¿å­˜éŸ³é¢‘æ–‡ä»¶
        with open(output_file, "wb") as f:
            f.write(response.content)

        # èŽ·å–éŸ³é¢‘æ—¶é•¿
        duration = get_audio_duration(output_file)

        return {
            "id": scene["id"],
            "title": scene["title"],
            "file": f"{scene['id']}.mp3",
            "duration": duration,
            "frames": round(duration * 30),
        }

    except Exception as e:
        # å¦‚æžœ OpenAI å®¢æˆ·ç«¯ä¸æ”¯æŒéŸ³é¢‘è¾“å‡ºï¼Œå°è¯• REST API
        print(f"æ³¨æ„: OpenAI å®¢æˆ·ç«¯è°ƒç”¨å¤±è´¥ï¼Œå°è¯• REST API: {e}")
        return generate_audio_rest_api(scene)


def generate_audio_rest_api(scene: dict) -> dict:
    """ä½¿ç”¨ REST API ç”ŸæˆéŸ³é¢‘ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰"""
    import requests

    url = f"{VLLM_BASE_URL.rstrip('/v1')}/v1/audio/speech"

    headers = {
        "Authorization": "Bearer EMPTY",
        "Content-Type": "application/json",
    }

    payload = {
        "model": VLLM_MODEL_NAME,
        "voice": VLLM_VOICE,
        "input": scene["text"],
        "response_format": "mp3",
    }

    response = requests.post(url, headers=headers, json=payload, timeout=120)

    if response.status_code == 200:
        output_file = OUTPUT_DIR / f"{scene['id']}.mp3"

        # vLLM-Omni å¯èƒ½è¿”å›ž WAV æ ¼å¼ï¼Œéœ€è¦æ£€æŸ¥
        content_type = response.headers.get("content-type", "")

        if "audio/wav" in content_type or output_file.suffix == ".wav":
            # ä¿å­˜ WAV æ–‡ä»¶
            wav_file = OUTPUT_DIR / f"{scene['id']}.wav"
            wav_file.write_bytes(response.content)

            # è½¬æ¢ä¸º MP3
            subprocess.run(
                [
                    "ffmpeg",
                    "-y",
                    "-i",
                    str(wav_file),
                    "-codec:a",
                    "libmp3lame",
                    "-b:a",
                    "128k",
                    str(output_file),
                ],
                capture_output=True,
            )

            # åˆ é™¤ä¸´æ—¶ WAV æ–‡ä»¶
            wav_file.unlink()
        else:
            # ç›´æŽ¥ä¿å­˜éŸ³é¢‘
            output_file.write_bytes(response.content)

        duration = get_audio_duration(output_file)

        return {
            "id": scene["id"],
            "title": scene["title"],
            "file": f"{scene['id']}.mp3",
            "duration": duration,
            "frames": round(duration * 30),
        }
    else:
        raise Exception(f"REST API é”™è¯¯: {response.status_code} - {response.text}")


def main():
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

    print(f"ðŸŽ™ï¸  vLLM-Omni Qwen3-TTS (Model: {VLLM_MODEL_NAME})")
    print(f"ðŸ“¡ æœåŠ¡å™¨: {VLLM_BASE_URL}")
    print(f"ðŸŽ­ è¯­éŸ³: {VLLM_VOICE}")
    print(f"ðŸ“ è¾“å‡ºç›®å½•: {OUTPUT_DIR}")
    print("=" * 60)

    results = []
    skipped = 0
    generated = 0

    for i, scene in enumerate(SCENES, 1):
        output_file = OUTPUT_DIR / f"{scene['id']}.mp3"
        prefix = f"[{i}/{len(SCENES)}] {scene['id']}"

        # æ–­ç‚¹ç»­ä½œï¼šæ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
        if output_file.exists() and output_file.stat().st_size > 0:
            duration = get_audio_duration(output_file)
            frames = round(duration * 30)
            results.append(
                {
                    "id": scene["id"],
                    "title": scene["title"],
                    "file": f"{scene['id']}.mp3",
                    "duration": duration,
                    "frames": frames,
                }
            )
            print(f"{prefix}: â­ï¸  å·²å­˜åœ¨ï¼Œè·³è¿‡ ({duration:.2f}s)")
            skipped += 1
            continue

        # ç”Ÿæˆæ–°éŸ³é¢‘
        print(f"{prefix}: ç”Ÿæˆä¸­...", end=" ", flush=True)
        try:
            result = generate_audio(scene)
            results.append(result)
            print(f"âœ… {result['duration']:.2f}s ({result['frames']} frames)")
            generated += 1
        except Exception as e:
            print(f"âŒ {e}")
            print("\nâš ï¸  ç”Ÿæˆä¸­æ–­ï¼Œå·²å®Œæˆçš„éŸ³é¢‘å·²ä¿å­˜ï¼Œå¯é‡æ–°è¿è¡Œç»§ç»­")
            return

    print("=" * 60)
    print(f"âœ… å®Œæˆ: {generated} æ–°ç”Ÿæˆ, {skipped} è·³è¿‡")

    # æ›´æ–° audioConfig.ts
    update_config(results)
    print(f"ðŸ“ audioConfig.ts å·²æ›´æ–°")


def update_config(results):
    """æ›´æ–° audioConfig.ts - æ³¨æ„ï¼šå¿…é¡»ç”¨çœŸæ­£çš„æ¢è¡Œç¬¦ï¼Œä¸èƒ½ç”¨å­—ç¬¦ä¸² \\n"""
    scenes_lines = []
    for r in results:
        # ä½¿ç”¨å¤šè¡Œå­—ç¬¦ä¸²ç¡®ä¿æ­£ç¡®çš„æ¢è¡Œ
        scene_block = f"""  {{
    id: "{r['id']}",
    title: "{r['title']}",
    durationInFrames: {r['frames']},
    audioFile: "{r['file']}",
  }}"""
        scenes_lines.append(scene_block)

    # ç”¨çœŸæ­£çš„æ¢è¡Œç¬¦è¿žæŽ¥ï¼Œä¸è¦ç”¨ ",\\n".join()
    scenes_content = ",\n".join(scenes_lines)

    content = f"""// åœºæ™¯é…ç½®ï¼ˆvLLM-Omni Qwen3-TTS ç”Ÿæˆï¼‰
// è‡ªåŠ¨ç”Ÿæˆï¼Œè¯·å‹¿æ‰‹åŠ¨ä¿®æ”¹

export interface SceneConfig {{
  id: string;
  title: string;
  durationInFrames: number;
  audioFile: string;
}}

export const SCENES: SceneConfig[] = [
{scenes_content},
];

// è®¡ç®—åœºæ™¯èµ·å§‹å¸§
export function getSceneStart(sceneIndex: number): number {{
  return SCENES.slice(0, sceneIndex).reduce((sum, s) => sum + s.durationInFrames, 0);
}}

// æ€»å¸§æ•°ï¼ˆåŠ ä¸Šç‰‡å¤´ç‰‡å°¾ç¼“å†²ï¼‰
export const TOTAL_FRAMES = SCENES.reduce((sum, s) => sum + s.durationInFrames, 0) + 60;

// å¸§çŽ‡
export const FPS = 30;
"""
    CONFIG_FILE.parent.mkdir(parents=True, exist_ok=True)
    CONFIG_FILE.write_text(content)


if __name__ == "__main__":
    main()
